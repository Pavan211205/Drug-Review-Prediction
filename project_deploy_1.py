# -*- coding: utf-8 -*-
"""project_deploy_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KnP3fQWnM8cSVpRF0uxiGoh3UBivv0c1
"""

import streamlit as st
import joblib
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer, PorterStemmer
from sklearn.linear_model import LogisticRegression
from sklearn.exceptions import NotFittedError
from sklearn.feature_extraction.text import TfidfVectorizer

# Download NLTK stuff
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('omw-1.4')

# Load models and vectorizer
try:
    model = joblib.load("logreg_model.pkl")
    vectorizer = joblib.load("tfidf_vectorizer.pkl")
    encoder = joblib.load("label_encoder.pkl")
except FileNotFoundError:
    st.error("Model files not found. Please ensure 'logreg_model.pkl', 'tfidf_vectorizer.pkl', and 'label_encoder.pkl' are in the same directory as your app.")
    st.stop() # Stop execution if files are not found


# Text cleaning function
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()
stemmer = PorterStemmer()

def clean_text(text):
    text = text.lower()
    text = re.sub(r'<.*?>', '', text)
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    tokens = text.split()
    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]
    tokens = [stemmer.stem(word) for word in tokens]
    return ' '.join(tokens)

# Streamlit UI
st.title("Drug Condition Prediction")
st.write("Enter a drug review and the model will predict if it's related to Depression, High Blood Pressure, or Type 2 Diabetes.")
user_input = st.text_area("Enter Drug Review:", "")

if st.button("Predict"):
    if not user_input.strip():
        st.warning("Please enter a valid review.")
    else:
        cleaned = clean_text(user_input)
        cleaned_words = set(cleaned.split())

        # Get the vocabulary used during training
        vectorizer_vocab = set(vectorizer.vocabulary_.keys())

        # Check if at least one word exists in training vocabulary
        if len(cleaned_words.intersection(vectorizer_vocab)) == 0:
            st.error("Invalid review. Please enter a proper drug experience like those used in training data.")
        elif len(cleaned_words) < 5:
            st.warning("Please write a more detailed review (at least 5 meaningful words).")
        else:
        
           try:
              # Get the feature names from the fitted vectorizer
              feature_names = vectorizer.get_feature_names_out()

              # Create a new vectorizer with the same vocabulary
              new_vectorizer = TfidfVectorizer(vocabulary=feature_names)

              # Transform the user input
              vectorized = new_vectorizer.fit_transform([cleaned])

              prediction = model.predict(vectorized)
              label = encoder.inverse_transform(prediction)[0]
              st.success(f"Predicted Condition: **{label}**")

           except NotFittedError as e:
              st.error(f"Error during prediction: {e}")
              st.error("The vectorizer or model might not be fitted properly.")
           except ValueError as e:
              st.error(f"Error during prediction: {e}")
              st.error("Please ensure your input resembles real review text.")
